{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "Torchvision version: 0.19.0\n",
      "Transformers version: 4.44.0\n",
      "MPS (Metal Performance Shaders) available: True\n",
      "Torchvision transforms available: True\n",
      "Torchvision models available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"MPS (Metal Performance Shaders) available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"Torchvision transforms available: {'transforms' in dir(torchvision)}\")\n",
    "print(f\"Torchvision models available: {'models' in dir(torchvision)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yigitaydede/opt/anaconda3/envs/huggingface_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' We are proposing two new undergraduate programs: A Bachelor of Commerce in Sports Business and a Bachelor of Arts in Sport, Health, & Wellness . The programs are aimed at equipping students with multidisciplinary skills needed to navigate the sport'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Explicitly specify the model and framework\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", framework=\"pt\")\n",
    "\n",
    "result = summarizer(\n",
    "    \"We are proposing two new undergraduate programs: a Bachelor of Commerce in Sports Business and a Bachelor of Arts in Sport, Health, & Wellness, aimed at equipping students with multidisciplinary skills needed to navigate the sport industry with social responsibility, ethical disposition, and sustainability in mind.\", \n",
    "    max_length=50, \n",
    "    min_length=25, \n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yigitaydede/opt/anaconda3/envs/huggingface_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Bachelor of Commerce in Sports Business and a Bachelor of Arts in Sport, Health, & Wellness are proposed . The programs are aimed at equipping students with multidisciplinary skills needed to navigate the sport industry . Both programs will incorporate hands-on learning experiences, internships, and collaborations with industry partners .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", framework=\"pt\")\n",
    "\n",
    "longer_text = \"\"\"\n",
    "We are proposing two new undergraduate programs: a Bachelor of Commerce in Sports Business and a Bachelor of Arts in Sport, Health, & Wellness. These programs are aimed at equipping students with multidisciplinary skills needed to navigate the sport industry with social responsibility, ethical disposition, and sustainability in mind. The Sports Business program will focus on the business aspects of sports, including management, marketing, and finance, while the Sport, Health, & Wellness program will emphasize the broader societal impacts of sports, including public health, community engagement, and personal well-being. Both programs will incorporate hands-on learning experiences, internships, and collaborations with industry partners to ensure students are well-prepared for careers in this dynamic field.\n",
    "\"\"\"\n",
    "\n",
    "result = summarizer(longer_text, max_length=75, min_length=30, do_sample=False)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll break down the entire process and explain what's happening behind the scenes with Hugging Face, the language model, and the summarization pipeline.\n",
    "\n",
    "1. Hugging Face and Transformers Library:\n",
    "   Hugging Face is a company that provides a popular library called Transformers, which offers pre-trained models and tools for natural language processing (NLP) tasks. The library simplifies the process of using state-of-the-art language models.\n",
    "\n",
    "2. Pipeline:\n",
    "   The `pipeline()` function from the Transformers library is a high-level API that abstracts away much of the complexity of using these models. It sets up all the necessary components for a specific NLP task.\n",
    "\n",
    "3. Language Model:\n",
    "   In your code, you're using the \"sshleifer/distilbart-cnn-12-6\" model. This is a specific version of DistilBART, which is a distilled (compressed) version of the BART model. BART is a transformer-based language model designed for sequence-to-sequence tasks like summarization.\n",
    "\n",
    "4. Summarization Task:\n",
    "   When you specify \"summarization\" as the task, the pipeline sets up the model specifically for text summarization. This involves:\n",
    "   - Loading the pre-trained weights for the specified model\n",
    "   - Setting up the tokenizer that converts text to numerical representations the model can understand\n",
    "   - Configuring the model for generation (since summarization is a text generation task)\n",
    "\n",
    "5. Input Processing:\n",
    "   When you pass your text to the summarizer, several things happen:\n",
    "   - The text is tokenized (split into subwords or word pieces)\n",
    "   - These tokens are converted to numerical IDs\n",
    "   - The IDs are passed through the model\n",
    "\n",
    "6. Model Operation:\n",
    "   The DistilBART model, being a sequence-to-sequence model, has an encoder and a decoder:\n",
    "   - The encoder processes the input text and creates a contextual representation\n",
    "   - The decoder then generates the summary based on this representation\n",
    "\n",
    "7. Generation Process:\n",
    "   The model generates the summary token by token. At each step, it considers:\n",
    "   - The encoded input\n",
    "   - The tokens it has generated so far\n",
    "   - The specified constraints (like max_length and min_length)\n",
    "\n",
    "8. Output Processing:\n",
    "   Once the model finishes generating, the pipeline:\n",
    "   - Decodes the generated token IDs back into text\n",
    "   - Applies any necessary post-processing (like removing special tokens)\n",
    "\n",
    "9. Result:\n",
    "   The pipeline returns the generated summary as a list of dictionaries, where each dictionary contains the 'summary_text' key with the generated summary as its value.\n",
    "\n",
    "- A note about hardware acceleration (suggesting you could potentially speed up the process by using a GPU)\n",
    "\n",
    "For best results with summarization models:\n",
    "1. Use longer input texts (paragraphs or full articles)\n",
    "2. Adjust the length parameters based on your input length and desired summary length\n",
    "3. Experiment with different pre-trained models that might be more suitable for your specific use case\n",
    "\n",
    "Remember, while these models are powerful, they work best within the parameters they were trained on, typically summarizing longer texts into concise versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's utilize our GPU on M1 MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      " A Bachelor of Commerce in Sports Business and a Bachelor of Arts in Sport, Health, & Wellness are proposed . The programs are aimed at equipping students with multidisciplinary skills needed to navigate the sport industry . Both programs will incorporate hands-on learning experiences, internships, and collaborations with industry partners .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Check if MPS is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create the summarization pipeline with the specified device\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", framework=\"pt\", device=device)\n",
    "\n",
    "# Your input text\n",
    "text = \"\"\"\n",
    "We are proposing two new undergraduate programs: a Bachelor of Commerce in Sports Business and a Bachelor of Arts in Sport, Health, & Wellness. These programs are aimed at equipping students with multidisciplinary skills needed to navigate the sport industry with social responsibility, ethical disposition, and sustainability in mind. The Sports Business program will focus on the business aspects of sports, including management, marketing, and finance, while the Sport, Health, & Wellness program will emphasize the broader societal impacts of sports, including public health, community engagement, and personal well-being. Both programs will incorporate hands-on learning experiences, internships, and collaborations with industry partners to ensure students are well-prepared for careers in this dynamic field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "result = summarizer(text, max_length=75, min_length=30, do_sample=False)\n",
    "\n",
    "# Print the result\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a simple object recognition code using a pre-trained model from Hugging Face to identify a cat in an image. We'll use the Vision Transformer (ViT) model, which is good for general image classification tasks.\n",
    "\n",
    "Here's a Python script that uses the Hugging Face Transformers library to perform object recognition on an image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "The image is classified as: patio, terrace\n",
      "\n",
      "Top 5 predictions:\n",
      "patio, terrace: 31.40%\n",
      "Egyptian cat: 10.62%\n",
      "tiger cat: 5.87%\n",
      "tabby, tabby cat: 3.71%\n",
      "soccer ball: 2.44%\n",
      "\n",
      "Total number of classes: 1000\n",
      "Range of class IDs: 0 to 999\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from PIL import Image\n",
    "\n",
    "# Set the environment variable to disable tokenizer parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Check if MPS is available (for M1 Macs)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained ViT model and image processor\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"/Users/yigitaydede/Library/CloudStorage/Dropbox/Documents/Courses/MBAN/NLPBootcamp/Section1/IMG_4697.jpeg\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Resize the image\n",
    "image = image.resize((224, 224))\n",
    "\n",
    "# Convert image to numpy array\n",
    "image_np = np.array(image)\n",
    "\n",
    "# Normalize the image\n",
    "image_np = (image_np / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# Convert to PyTorch tensor and add batch dimension\n",
    "input_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "# Move input to the appropriate device\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_idx = outputs.logits.argmax(-1).item()\n",
    "predicted_class = model.config.id2label.get(predicted_class_idx, f\"Unknown (ID: {predicted_class_idx})\")\n",
    "\n",
    "# Print the result\n",
    "print(f\"The image is classified as: {predicted_class}\")\n",
    "\n",
    "# If you want to see the top 5 predictions:\n",
    "top5_prob, top5_catid = torch.topk(outputs.logits.softmax(dim=-1)[0], 5)\n",
    "print(\"\\nTop 5 predictions:\")\n",
    "for i in range(5):\n",
    "    class_id = top5_catid[i].item()\n",
    "    class_name = model.config.id2label.get(class_id, f\"Unknown (ID: {class_id})\")\n",
    "    print(f\"{class_name}: {top5_prob[i].item()*100:.2f}%\")\n",
    "\n",
    "# Print the total number of classes\n",
    "print(f\"\\nTotal number of classes: {len(model.config.id2label)}\")\n",
    "print(f\"Range of class IDs: 0 to {len(model.config.id2label) - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the code step by step:\n",
    "\n",
    "1. Import necessary libraries:\n",
    "```python\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from PIL import Image\n",
    "```\n",
    "- `os`: For setting environment variables\n",
    "- `torch`: PyTorch library for tensor computations and neural networks\n",
    "- `numpy`: For numerical operations on arrays\n",
    "- `transformers`: Hugging Face library for using pre-trained models\n",
    "- `PIL`: Python Imaging Library for opening and manipulating images\n",
    "\n",
    "2. Set up the environment:\n",
    "```\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "```\n",
    "This line disables parallelism in the tokenizers library to avoid potential issues with forked processes.\n",
    "\n",
    "3. Set up the device:\n",
    "```\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "```\n",
    "This checks if MPS (Metal Performance Shaders) is available on Mac M1 chips. If it is, we use it; otherwise, we fall back to CPU.\n",
    "\n",
    "4. Load the pre-trained model and image processor:\n",
    "```\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model = model.to(device)\n",
    "```\n",
    "We're loading a pre-trained Vision Transformer model and its associated image processor. The model is then moved to the appropriate device (MPS or CPU).\n",
    "\n",
    "5. Load and preprocess the image:\n",
    "```\n",
    "image_path = \"/path/to/your/image.jpeg\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize((224, 224))\n",
    "```\n",
    "We open the image, convert it to RGB format (in case it's not already), and resize it to 224x224 pixels, which is the input size expected by this ViT model. RGB stands for Red, Green, and Blue. It's a color model used in digital imaging and displays. It's the standard color model used in most digital displays, including computer monitors, smartphones, and televisions.\n",
    "\n",
    "6. Convert the image to a numpy array and normalize it:\n",
    "```\n",
    "image_np = np.array(image)\n",
    "image_np = (image_np / 255.0 - 0.5) / 0.5\n",
    "```\n",
    "This line converts the PIL Image object to a numpy array. The resulting array has shape (224, 224, 3), where 224x224 is the image size, and 3 represents the RGB channels. Each value in this array is an integer between 0 and 255, representing the intensity of red, green, or blue for each pixel. We convert the image to a numpy array and normalize its values. The normalization step maps the pixel values from [0, 255] to [-1, 1], which is often beneficial for neural networks.\n",
    "\n",
    "7. Convert to PyTorch tensor:\n",
    "```\n",
    "input_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float()\n",
    "input_tensor = input_tensor.to(device)\n",
    "```\n",
    "We convert the numpy array to a PyTorch tensor, rearrange its dimensions (from HWC to CHW format), add a batch dimension, convert to float, and move it to the appropriate device. PyTorch tensors are similar to numpy arrays but can be processed on GPUs and are designed for automatic differentiation, which is crucial for neural networks.  This is currical step in NN using PyTorch or Tensorflow.  Please see \"tensor.ipynb\".\n",
    "\n",
    "8. Perform inference:\n",
    "```\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "```\n",
    "We run the image through the model. The `with torch.no_grad():` context ensures that we're not tracking gradients, which is not necessary for inference and saves memory.\n",
    "\n",
    "9. Get and print the top prediction:\n",
    "```\n",
    "predicted_class_idx = outputs.logits.argmax(-1).item()\n",
    "predicted_class = model.config.id2label.get(predicted_class_idx, f\"Unknown (ID: {predicted_class_idx})\")\n",
    "print(f\"The image is classified as: {predicted_class}\")\n",
    "```\n",
    "We get the index of the highest logit, convert it to a class label using the model's `id2label` mapping, and print the result.\n",
    "\n",
    "10. Get and print the top 5 predictions:\n",
    "```\n",
    "top5_prob, top5_catid = torch.topk(outputs.logits.softmax(dim=-1)[0], 5)\n",
    "print(\"\\nTop 5 predictions:\")\n",
    "for i in range(5):\n",
    "    class_id = top5_catid[i].item()\n",
    "    class_name = model.config.id2label.get(class_id, f\"Unknown (ID: {class_id})\")\n",
    "    print(f\"{class_name}: {top5_prob[i].item()*100:.2f}%\")\n",
    "```\n",
    "We get the top 5 predictions, their probabilities, and print them. We use `get()` on `id2label` to handle cases where the ID might not be in the mapping.\n",
    "\n",
    "11. Print information about the model's classes:\n",
    "```python\n",
    "print(f\"\\nTotal number of classes: {len(model.config.id2label)}\")\n",
    "print(f\"Range of class IDs: 0 to {len(model.config.id2label) - 1}\")\n",
    "```\n",
    "This gives us information about the number of classes the model can predict and the range of class IDs.\n",
    "\n",
    "This code demonstrates the full pipeline of loading a pre-trained model, preprocessing an image, running inference, and interpreting the results. It's a great example for students to understand how deep learning models are used for practical tasks like image classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
