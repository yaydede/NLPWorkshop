{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Application\n",
    "\n",
    "\n",
    "## Application with Word Embedding\n",
    "\n",
    "The dataset we are using here is a subset of Amazon reviews from the Cell Phones & Accessories category. The data is stored as a JSON file and can be read using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin      reviewerName helpful  \\\n",
      "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
      "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
      "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
      "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
      "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  They look good and stick good! I just don't li...        4   \n",
      "1  These stickers work like the review says they ...        5   \n",
      "2  These are awesome and make my phone look so st...        5   \n",
      "3  Item arrived in great time and was in perfect ...        4   \n",
      "4  awesome! stays on, and looks great. can be use...        5   \n",
      "\n",
      "                                     summary  unixReviewTime   reviewTime  \n",
      "0                                 Looks Good      1400630400  05 21, 2014  \n",
      "1                      Really great product.      1389657600  01 14, 2014  \n",
      "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
      "3                                      Cute!      1382313600  10 21, 2013  \n",
      "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  \n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\"\n",
    "\n",
    "# Send a HTTP request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Make sure the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open the response content as a gzip file\n",
    "    with gzip.open(BytesIO(response.content), 'rt') as read_file:\n",
    "        # Read the dataset into a pandas DataFrame\n",
    "        data = pd.read_json(read_file, lines=True)\n",
    "    # Display the first few rows of the DataFrame\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"Failed to download the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [they, look, good, and, stick, good, just, don...\n",
       "1         [these, stickers, work, like, the, review, say...\n",
       "2         [these, are, awesome, and, make, my, phone, lo...\n",
       "3         [item, arrived, in, great, time, and, was, in,...\n",
       "4         [awesome, stays, on, and, looks, great, can, b...\n",
       "                                ...                        \n",
       "194434    [works, great, just, like, my, original, one, ...\n",
       "194435    [great, product, great, packaging, high, quali...\n",
       "194436    [this, is, great, cable, just, as, good, as, t...\n",
       "194437    [really, like, it, becasue, it, works, well, w...\n",
       "194438    [product, as, described, have, wasted, lot, of...\n",
       "Name: reviewText, Length: 194439, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = data.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=35561, vector_size=100, alpha=0.025>\n",
      "Vector for the word 'phone': [-6.3998312e-01 -1.4190605e+00  2.1279287e+00 -1.4021382e+00\n",
      " -1.8854320e+00  6.1295718e-01 -2.1259439e+00  3.4396327e-01\n",
      "  2.7594447e+00  1.8673247e+00  2.1820788e+00 -1.5625589e+00\n",
      " -1.0210887e+00 -4.2885270e+00  1.1849930e+00  2.4339321e+00\n",
      " -1.4142124e-01  3.2184696e+00  3.4006277e-01 -1.9219936e-01\n",
      " -1.2596589e+00  1.3896925e+00  3.5460535e-01  3.5005484e+00\n",
      " -1.1138523e+00 -1.9386652e-01  2.0508106e+00  3.2048085e+00\n",
      " -5.4209900e-01  8.1116128e-01  4.0708828e+00 -3.0688353e+00\n",
      "  4.1906486e+00 -8.3819085e-01  1.8337253e+00 -1.8341529e-01\n",
      "  1.7472942e+00 -3.1700909e+00 -1.3498080e+00  5.2830368e-01\n",
      " -3.3253145e-01  3.2028456e+00  1.4030707e+00 -1.9721323e+00\n",
      "  1.4377276e+00 -5.1707673e-01  5.0323230e-01 -2.5271021e-03\n",
      "  1.1227527e+00  1.2285974e+00  2.1387091e+00  3.6197749e-01\n",
      " -1.8539317e+00 -3.4891474e+00  2.3794155e+00 -2.7587482e-01\n",
      " -1.1417617e+00  2.1127207e+00  4.0166011e+00  3.9557195e+00\n",
      " -9.6112138e-01 -9.4898123e-01 -8.1825972e-01 -6.9595331e-01\n",
      " -7.2722286e-01 -2.7970753e+00  5.0387913e-01 -7.0612466e-01\n",
      "  3.2348869e+00  1.3254284e+00  1.9760980e-01 -4.2392923e-03\n",
      "  1.6779608e+00  7.7877349e-01 -1.8574474e+00  2.7748349e+00\n",
      "  3.8483045e-01 -8.1501454e-01  7.5008643e-01  1.2576602e+00\n",
      "  1.5949243e+00  4.0929413e+00 -9.7451530e-02  3.3338866e+00\n",
      " -1.5133820e+00 -1.8745378e+00 -1.6799613e+00 -1.0935811e+00\n",
      " -1.5883350e+00 -1.0948485e+00 -1.7375724e+00 -3.8389690e+00\n",
      " -2.4460995e-01 -4.2787728e+00  5.0258726e-01 -6.0038421e-02\n",
      "  2.5305420e-01 -1.6148015e+00 -9.1918811e-02 -1.5287780e+00]\n",
      "Words similar to 'phone': [('cellphone', 0.5534300208091736), ('iphone', 0.5523996949195862), ('it', 0.5204033255577087), ('lap', 0.4828510284423828), ('case', 0.48228737711906433), ('device', 0.4691130518913269), ('tabletcons', 0.46793413162231445), ('cheek', 0.4507414400577545), ('pocket', 0.4323415160179138), ('face', 0.42945826053619385)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Convert review_text into a list of lists of tokens for training\n",
    "sentences = review_text.tolist()\n",
    "\n",
    "# Initialize and train the Word2Vec model\n",
    "model = Word2Vec(sentences=sentences,\n",
    "                 vector_size=100,  # Size of word vectors; adjust based on your needs\n",
    "                 window=10,\n",
    "                 min_count=2,\n",
    "                 workers=4)\n",
    "\n",
    "# Summarize the loaded model\n",
    "print(model)\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"word2vec_amazon_reviews.model\")\n",
    "\n",
    "# Access vectors for a word\n",
    "print(\"Vector for the word 'phone':\", model.wv['phone'])\n",
    "\n",
    "# Find most similar words to 'phone'\n",
    "print(\"Words similar to 'phone':\", model.wv.most_similar('phone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61505184, 83868975)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(review_text, progress_per=1000)\n",
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number (61502857): This is the total number of words processed during the training phase. It takes into account the window parameter and possibly multiple passes over the data, depending on the number of epochs the model is trained for. This number shows how many individual word contexts the training algorithm has used to adjust the vector representations.\n",
    "\n",
    "The second number (83868975): This is the total number of raw words in the training data. It represents the sum of the lengths of all the sentences provided to the model as training data, before any filtering for min_count (minimum word frequency) or other preprocessing steps. Essentially, it's the size of the training corpus in terms of total words before any words are excluded based on the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shabby', 0.6256607174873352),\n",
       " ('terrible', 0.6220461130142212),\n",
       " ('good', 0.5864471793174744),\n",
       " ('horrible', 0.5709187388420105),\n",
       " ('disappointing', 0.5291851758956909),\n",
       " ('poor', 0.5196760892868042),\n",
       " ('fault', 0.5156261920928955),\n",
       " ('sad', 0.515142560005188),\n",
       " ('okay', 0.49805721640586853),\n",
       " ('cheap', 0.4978519678115845)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"great\", w2=\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7913931"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Similar Words\n",
    "\n",
    "After we've trained your Word2Vec model on customer reviews, we've essentially transformed words into vectors that capture semantic meanings, relationships, and context within our dataset. This opens up a variety of ways to analyze and gain insights from the customer reviews. Here are some practical applications and analyses we can perform:\n",
    "\n",
    "1. Finding Similar Words (we did already)\n",
    "Discover words that are semantically related to specific terms. This can help identify common themes or issues in reviews. For example, finding words similar to \"battery\" might reveal related concerns or praises in the context of product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batter', 0.8712946176528931), ('batt', 0.8024268746376038), ('batteries', 0.6934431791305542), ('juice', 0.5941666960716248), ('powerplant', 0.583953857421875), ('cycle', 0.5682535767555237), ('powerbank', 0.5618174076080322), ('igeek', 0.5543268918991089), ('incredicharge', 0.5326968431472778), ('ion', 0.5305150747299194)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar('battery', topn=10)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why the `train` method is sometimes used separately in Gensim’s Word2Vec.\n",
    "\n",
    "1. Incremental Training (Online Learning):\n",
    "\n",
    "Incremental training (also known as online learning) is when you want to train your model on new data without starting from scratch. Here’s why it might be useful:\n",
    "\n",
    "- Dynamic Data: Suppose you continuously receive new data (like real-time reviews or social media posts). Instead of retraining the model from the beginning every time new data arrives, you can load the existing model and use train to update it with the new data.\n",
    "- Memory Efficiency: When working with very large datasets, you might not have all the data available at once. You can build your model incrementally, feeding in data in chunks.\n",
    "\n",
    "2. Custom Vocabulary Building:\n",
    "Separating vocabulary building and training is useful when:\n",
    "\n",
    "- Inspecting the Vocabulary: You might want to inspect or fine-tune the vocabulary before training, for example by adjusting min_count (which controls the minimum frequency for a word to be included in the model).\n",
    "- Adjusting Hyperparameters: After inspecting the vocabulary, you might decide to tweak hyperparameters like window, vector_size, or min_count before proceeding to the training phase.\n",
    "\n",
    "In this case, you build the vocabulary first, then call train explicitly when you’re ready.\n",
    "\n",
    "3. Fine-Tuning a Pre-Trained Model:\n",
    "Sometimes you start with a pre-trained model and then fine-tune it on a smaller, domain-specific dataset. For instance:\n",
    "\n",
    "- Domain Adaptation: If you have a Word2Vec model trained on general text (like news articles), you might want to adapt it to a specific domain like medical text or legal documents.\n",
    "- Improving Performance: Fine-tuning on new data can improve performance for tasks specific to your domain, such as document classification or sentiment analysis.\n",
    "\n",
    "In these cases, you load the pre-trained model and use train to update the word vectors based on your new data.\n",
    "\n",
    "Let's see how exactly you can load and continue training your model with additional data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = Word2Vec.load(\"word2vec_amazon_reviews.model\")\n",
    "\n",
    "new_reviews = [\n",
    "    \"I love this phone, it has great battery life\",\n",
    "    \"The camera on this phone is amazing but the battery drains quickly\",\n",
    "    \"Highly recommended phone for its price\"\n",
    "]\n",
    "\n",
    "# Preprocess the new reviews (using the same preprocessing steps)\n",
    "new_sentences = [gensim.utils.simple_preprocess(review) for review in new_reviews]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing training, you need to update the model’s vocabulary with the new words in your additional data. Use build_vocab with the `update=True` option, which ensures that the existing vocabulary is retained, and the new words are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(new_sentences, update=True)\n",
    "model.train(new_sentences, total_examples=len(new_sentences), epochs=model.epochs)\n",
    "model.save(\"word2vec_amazon_reviews_updated.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`total_examples=len(new_sentences)`: This tells the model how many examples (sentences) you’re training it on.\n",
    "`epochs=model.epochs`: This ensures the new data is trained for the same number of epochs as your original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the Process:\n",
    "- Model Name: The initial model is saved as `word2vec_amazon_reviews.model`.  \n",
    "- Loading and Updating: You load the model, add new data, and then retrain it incrementally.\n",
    "- Vocabulary Update: Remember to use `build_vocab(..., update=True)` when adding new data to ensure the new words are incorporated into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'phone' after incremental training: [('cellphone', 0.5536061525344849), ('iphone', 0.5523805022239685), ('it', 0.5207656025886536), ('lap', 0.4834569990634918), ('case', 0.4824077785015106), ('device', 0.46920591592788696), ('tabletcons', 0.46835488080978394), ('cheek', 0.4509800672531128), ('pocket', 0.43245789408683777), ('face', 0.42960381507873535)]\n"
     ]
    }
   ],
   "source": [
    "# Check updated vectors\n",
    "print(\"Words similar to 'phone' after incremental training:\", model.wv.most_similar('phone'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Learning vs. Fine-Tuning\n",
    "Fine-tuning and incremental learning might seem similar at first glance, but they serve slightly different purposes and are used in different contexts.\n",
    "\n",
    "1. The purpose of Incremetal Learning is to continue training the model with new data as it becomes available while retaining knowledge from the existing model. It's suitable for scenarios where you receive new data continuously (e.g., streaming data or new customer reviews) and want to update the model without retraining it from scratch.\n",
    "The model’s vocabulary and knowledge are expanded to incorporate the new data. You load the model, update the vocabulary, and train it on the new data.\n",
    "2. In Fine-Tuning, the purpose is to adapt a pre-trained model to a specific domain or task. You fine-tune the model on a smaller, domain-specific dataset while retaining the general knowledge from the pre-training phase. It's useful when you want to apply a model pre-trained on a large general corpus (e.g., news articles, Wikipedia) to a specialized task (e.g., medical text analysis, legal documents). The model is trained further on a small dataset specific to the new task, usually with adjusted hyperparameters (e.g., lower learning rate, fewer epochs) to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'phone' after fine-tuning: [('cellphone', 0.5534407496452332), ('iphone', 0.5522252321243286), ('it', 0.5205486416816711), ('lap', 0.48235467076301575), ('case', 0.482332319021225), ('device', 0.4693024456501007), ('tabletcons', 0.4679739475250244), ('cheek', 0.45062342286109924), ('pocket', 0.4320789873600006), ('face', 0.4295228123664856)]\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = Word2Vec.load(\"word2vec_amazon_reviews.model\")\n",
    "\n",
    "# Specialized data for fine-tuning\n",
    "fine_tuning_reviews = [\n",
    "    \"The battery life of this phone is exceptional.\",\n",
    "    \"I found the screen resolution to be subpar.\",\n",
    "    \"This smartphone offers a great balance between price and performance.\"\n",
    "]\n",
    "\n",
    "# Preprocess the reviews\n",
    "fine_tuning_sentences = [gensim.utils.simple_preprocess(review) for review in fine_tuning_reviews]\n",
    "\n",
    "# Optionally update the vocabulary\n",
    "model.build_vocab(fine_tuning_sentences, update=True)\n",
    "\n",
    "# Fine-tune the model with a lower learning rate and fewer epochs\n",
    "model.train(fine_tuning_sentences, total_examples=len(fine_tuning_sentences), epochs=5)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save(\"word2vec_amazon_reviews_finetuned.model\")\n",
    "\n",
    "# Check results\n",
    "print(\"Words similar to 'phone' after fine-tuning:\", model.wv.most_similar('phone'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, fine-tuning adapts your model for a specific domain or task, while incremental learning keeps your model up-to-date with new data. Fine-tuning typically involves more cautious training to avoid losing the general knowledge your model has already gained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clustering\n",
    "\n",
    "Clustering words based on their vector representations can help identify groups of related terms or concepts within the reviews. Techniques like K-means clustering can be applied to the word vectors to group words into clusters of similar meanings. Word clustering involves grouping words into clusters based on their vector representations, such that words in the same cluster have similar meanings or are used in similar contexts. This can reveal patterns, themes, or topics common in your data. For instance, in customer reviews, you might find clusters around product features, customer service, shipping issues, etc.   \n",
    "\n",
    "Let's demonstrate word clustering using K-means on the Word2Vec embeddings you've trained. We'll use a subset of the most frequent words to make the clusters more interpretable. Finally, we'll discuss the insights that can be gained from this analysis.\n",
    "  \n",
    "**Step 1: Preparing Word Vectors**\n",
    "First, extract a set of word vectors from your Word2Vec model. For demonstration, we'll use the 100 most frequent words (excluding very common but less informative words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `model` is your Word2Vec model\n",
    "\n",
    "# Extract the list of words & their vectors\n",
    "word_vectors = model.wv.vectors\n",
    "words = list(model.wv.index_to_key)\n",
    "\n",
    "# For a more focused analysis, consider filtering words by frequency or excluding stop words\n",
    "# This example uses all words for simplicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Clustering Words**\n",
    "Now, we'll use K-means clustering to group these words into clusters based on their vector similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 10  # Example: 10 clusters. Adjust based on your analysis needs.\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(word_vectors)\n",
    "\n",
    "# Assign each word to a cluster\n",
    "word_cluster_labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Examining the Clusters**\n",
    "After clustering, let's examine which words ended up in the same clusters. This will give us an idea of the themes or topics present in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of word clusters\n",
    "word_clusters = {i: [] for i in range(k)}\n",
    "for word, cluster_label in zip(words, word_cluster_labels):\n",
    "    word_clusters[cluster_label].append(word)\n",
    "\n",
    "# Display words in each cluster\n",
    "for cluster, words in word_clusters.items():\n",
    "    print(f\"Cluster {cluster}: {words[:10]}\")  # Displaying first 10 words for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights from Word Clustering**.\n",
    "\n",
    "- Theme Identification: Each cluster represents a group of words that are contextually similar. By examining the words in each cluster, you can identify common themes or topics in the reviews. For example, a cluster containing words like \"battery\", \"charge\", and \"power\" might indicate discussions about battery life.\n",
    "- Product Features and Issues: Clusters might reveal specific product features that customers talk about the most, as well as recurring issues or areas of dissatisfaction.\n",
    "- Customer Sentiment: Although not a direct measure of sentiment, the clustering of certain words together can give clues about overall customer sentiment. Words with positive connotations clustering together separately from words with negative connotations could indicate polarized opinions about certain aspects of the product or service.\n",
    "- Improving Product and Service: By identifying clusters related to customer service, shipping, product durability, etc., businesses can pinpoint areas for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference in K-Means**\n",
    "The approach of finding \"similar words\" using Word2Vec (like with `most_similar`) and clustering words using techniques like K-means are related but serve different purposes and work in slightly different ways. Let’s break down the distinctions and relationships between these approaches:\n",
    "\n",
    "1. Finding Similar Words (using most_similar): The primary goal is to identify words that are closest in vector space to a given target word. Word2Vec learns vector representations (embeddings) where words that appear in similar contexts have similar vectors. The most_similar method identifies words whose vectors are closest to a target word’s vector, based on cosine similarity.\n",
    "\n",
    "It’s often used for synonym detection, expanding queries, or understanding context in NLP tasks. For example, given the word \"phone,\" it might return words like \"mobile,\" \"smartphone,\" \"device,\" etc., which are semantically related.\n",
    "\n",
    "2. Clustering Words (using K-means): The goal is to group words into clusters based on their vector representations. Each cluster represents a group of words that are close to each other in vector space. K-means clustering algorithm groups word vectors into a specified number of clusters (k). The algorithm iteratively assigns words to the nearest cluster centroid and adjusts the centroids until the clusters stabilize.\n",
    "\n",
    "It’s used for tasks like topic modeling, organizing vocabulary into themes, or understanding word groups in a large corpus.  For example, you might get clusters where one cluster contains words related to \"technology\" (e.g., \"phone,\" \"tablet,\" \"laptop\"), while another contains words related to \"battery life\" (e.g., \"charging,\" \"drains,\" \"power\").\n",
    "\n",
    "In practice, you can use both methods together:\n",
    "\n",
    "- First Step: Use K-means clustering to identify broad categories of words.\n",
    "- Second Step: Within each cluster, you can then use most_similar to explore finer relationships and identify the most representative words in that cluster.\n",
    "\n",
    "After performing K-means clustering, you might also want to visualize the clusters using techniques like t-SNE or PCA, which project the high-dimensional word vectors into 2D space for better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "To demonstrate sentiment analysis using the same Amazon review data, I’ll walk you through both supervised (with labeled data) and unsupervised (without labeled data) methods. Sentiment analysis typically involves determining whether a piece of text has a positive, negative, or neutral sentiment.\n",
    "\n",
    "Here’s how you can approach it:\n",
    "\n",
    "### 1. **Sentiment Analysis with Labeled Data (Supervised Learning)**:\n",
    "\n",
    "In supervised learning, you need labeled data where each review has a corresponding sentiment label (e.g., positive, negative). We'll explore how to use machine learning models like Logistic Regression or even advanced methods like fine-tuning pre-trained transformer models.\n",
    "\n",
    "2. **Sentiment Analysis without Labeled Data (Unsupervised Learning)**:\n",
    "In unsupervised learning, you don’t have labels, so you use heuristic-based approaches like:\n",
    "\n",
    "- Lexicon-based methods: Use pre-built dictionaries of positive and negative words.\n",
    "- Unsupervised clustering methods: Group reviews into clusters that represent sentiment.\n",
    "\n",
    "Let's start with the unsupervised approach.\n",
    "\n",
    "## Lexicon-Based Approach - Unsupervised\n",
    "  \n",
    "This method relies on predefined lists of words associated with positive and negative sentiments. You can use libraries like TextBlob or VADER, which come with built-in sentiment lexicons and can provide sentiment scores based on the presence and combinations of positive and negative words in your text.\n",
    "\n",
    "**Method 1: Lexicon-Based Approach using `TextBlob`**\n",
    "`TextBlob` is a simple and widely used library for sentiment analysis that doesn’t require labeled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment polarity: 5.551115123125783e-17\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Example review\n",
    "review = \"The phone has an amazing battery life but a disappointing camera.\"\n",
    "\n",
    "# Get sentiment polarity\n",
    "sentiment = TextBlob(review).sentiment.polarity\n",
    "print(f\"Sentiment polarity: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive polarity score indicates a positive sentiment, while a negative score indicates a negative sentiment. TextBlob can be a straightforward way to start with sentiment analysis without needing labeled data.\n",
    "\n",
    "This method relies on predefined sentiment scores for words to evaluate the overall sentiment of a piece of text. Two popular tools for this purpose are TextBlob and VADER (Valence Aware Dictionary and sEntiment Reasoner), both of which are well-suited for different types of text data. Here, I'll show you how to use both, and you can choose based on your preference and the nature of your dataset.\n",
    "\n",
    "TextBlob is straightforward and works well for general-purpose sentiment analysis, including on longer texts like reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying TextBlob sentiment analysis on the reviewText column\n",
    "data['sentiment_polarity'] = data['reviewText'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "data['sentiment_subjectivity'] = data['reviewText'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjectivity in sentiment analysis measures how much a piece of text reflects personal opinions, emotions, and judgments rather than objective facts. The subjectivity score ranges from 0 to 1.\n",
    "- 0 (Objective): A score closer to 0 indicates that the text is more objective, meaning it contains factual information with little to no personal opinion or emotion.\n",
    "- 1 (Subjective): A score closer to 1 indicates that the text is highly subjective, meaning it is based more on personal opinions, feelings, or beliefs rather than facts.\n",
    "\n",
    "\n",
    "Objective Text (Score Near 0):\n",
    "\n",
    "Examples: “The phone weighs 200 grams.” or “The sky is blue.”\n",
    "These statements provide factual information without expressing personal thoughts or emotions. Such text would have a low subjectivity score because it’s focused on facts rather than opinions.\n",
    "  \n",
    "Subjective Text (Score Near 1):\n",
    "  \n",
    "Examples: “I love how lightweight this phone is!” or “The movie was amazing and heartwarming.”\n",
    "These statements express personal opinions and feelings. The language is driven by individual perception rather than facts. Such text would have a high subjectivity score because it is based on emotions, preferences, and judgments.\n",
    "Application in Sentiment Analysis:\n",
    "In tasks like sentiment analysis or opinion mining, determining the subjectivity helps in distinguishing between:\n",
    "\n",
    "Objective Reviews or Comments: These are more likely to provide factual information that can be useful in different contexts.\n",
    "Subjective Reviews or Comments: These contain opinions that help in understanding user preferences, satisfaction, or dissatisfaction.\n",
    "\n",
    "Example Use Case: Suppose you have product reviews, and you want to focus on opinions (subjective content) rather than purely descriptive (objective) content. A subjectivity score allows you to filter reviews based on whether they reflect factual descriptions or personal experiences and emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have sentiment scores, you can analyze them to gain insights into the overall sentiment of the reviews, such as:\n",
    "Overall Sentiment: Calculate the average sentiment polarity to get an idea of the overall sentiment towards the product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiment Polarity: 0.24830300849739492\n"
     ]
    }
   ],
   "source": [
    "average_sentiment = data['sentiment_polarity'].mean()\n",
    "print(f\"Average Sentiment Polarity: {average_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average sentiment polarity of approximately 0.248 suggests that the overall sentiment in your dataset of reviews leans towards the positive side. This is a good starting point for understanding customer sentiment, but there are several ways you can delve deeper to gain more nuanced insights.  Now that we know the overall sentiment is somewhat positive, we might want to understand how sentiment varies across different aspects or features of the product, like its battery life, camera quality, or customer service. We can filter reviews mentioning specific features and calculate the average sentiment for reviews concerning each aspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews: 172070\n",
      "Neutral Reviews: 4950\n",
      "Negative Reviews: 17419\n"
     ]
    }
   ],
   "source": [
    "positive_reviews = data[data['sentiment_polarity'] > 0].shape[0]\n",
    "neutral_reviews = data[data['sentiment_polarity'] == 0].shape[0]\n",
    "negative_reviews = data[data['sentiment_polarity'] < 0].shape[0]\n",
    "\n",
    "print(f\"Positive Reviews: {positive_reviews}\")\n",
    "print(f\"Neutral Reviews: {neutral_reviews}\")\n",
    "print(f\"Negative Reviews: {negative_reviews}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment for battery: 0.199119172408153\n",
      "Average sentiment for camera: 0.19423316438082053\n",
      "Average sentiment for service: 0.22639224564186428\n"
     ]
    }
   ],
   "source": [
    "features = ['battery', 'camera', 'service']\n",
    "for feature in features:\n",
    "    feature_reviews = data[data['reviewText'].str.contains(feature, case=False)]\n",
    "    avg_sentiment = feature_reviews['sentiment_polarity'].mean()\n",
    "    print(f\"Average sentiment for {feature}: {avg_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop a script that we follow in both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          reviewText  sentiment_score  \\\n",
      "0  They look good and stick good! I just don't li...         0.391667   \n",
      "1  These stickers work like the review says they ...         0.533333   \n",
      "2  These are awesome and make my phone look so st...         0.573828   \n",
      "3  Item arrived in great time and was in perfect ...         0.600000   \n",
      "4  awesome! stays on, and looks great. can be use...         0.360000   \n",
      "\n",
      "  sentiment  \n",
      "0  positive  \n",
      "1  positive  \n",
      "2  positive  \n",
      "3  positive  \n",
      "4  positive  \n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(review):\n",
    "    analysis = TextBlob(review)\n",
    "    return analysis.sentiment.polarity  # Returns a score between -1 (negative) and 1 (positive)\n",
    "\n",
    "# Apply sentiment analysis to your dataset\n",
    "data['sentiment_score'] = data['reviewText'].apply(get_sentiment)\n",
    "\n",
    "# Classify sentiment based on score\n",
    "data['sentiment'] = data['sentiment_score'].apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral'))\n",
    "\n",
    "# Display results\n",
    "print(data[['reviewText', 'sentiment_score', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: Lexicon-Based Approach using VADER (for Social Media/Informal Text)**\n",
    "\n",
    "VADER is specifically tuned for social media text, making it useful for analyzing informal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          reviewText  vader_sentiment  \\\n",
      "0  They look good and stick good! I just don't li...           0.5396   \n",
      "1  These stickers work like the review says they ...           0.9403   \n",
      "2  These are awesome and make my phone look so st...           0.8852   \n",
      "3  Item arrived in great time and was in perfect ...           0.9625   \n",
      "4  awesome! stays on, and looks great. can be use...           0.9020   \n",
      "\n",
      "  vader_label  \n",
      "0    positive  \n",
      "1    positive  \n",
      "2    positive  \n",
      "3    positive  \n",
      "4    positive  \n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(review):\n",
    "    sentiment_dict = analyzer.polarity_scores(review)\n",
    "    return sentiment_dict['compound']  # Returns a score between -1 (negative) and 1 (positive)\n",
    "\n",
    "data['vader_sentiment'] = data['reviewText'].apply(vader_sentiment)\n",
    "data['vader_label'] = data['vader_sentiment'].apply(lambda x: 'positive' if x > 0.05 else ('negative' if x < -0.05 else 'neutral'))\n",
    "\n",
    "# Display results\n",
    "print(data[['reviewText', 'vader_sentiment', 'vader_label']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'love': [-0.03944132  0.00803429 -0.10351574 -0.1920672 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/YigitAydede/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define the dataset\n",
    "comments = [\"love the new features\", \"hate the long wait time\", \"excellent service\", \"poor experience with the product\", \"happy with the purchase\"]\n",
    "sentiments = [1, 0, 1, 0, 1]  # 1: Positive, 0: Negative\n",
    "\n",
    "# Download the punkt tokenizer models\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Now you can proceed with tokenizing your text\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_comments = [word_tokenize(comment.lower()) for comment in comments]\n",
    "\n",
    "# Train word embeddings\n",
    "model = Word2Vec(tokenized_comments, vector_size=4, window=2, min_count=1, workers=1)\n",
    "\n",
    "# View a sample word vector\n",
    "print(\"Vector for 'love':\", model.wv['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average vector for first comment: [-0.01083414 -0.0337788   0.03695674  0.03914206]\n",
      "Average vector for first comment: [ 0.01442597  0.04124683 -0.09715094  0.0698698 ]\n",
      "Average vector for first comment: [ 0.02520601 -0.14069088 -0.12306689 -0.03584729]\n",
      "Average vector for first comment: [ 0.03350125 -0.02111864  0.04544426  0.07532134]\n",
      "Average vector for first comment: [-0.12119516 -0.02556053  0.08801746  0.09145366]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate average word vectors for each comment\n",
    "average_vectors = []\n",
    "for comment in tokenized_comments:\n",
    "  comment_vector = np.zeros(model.vector_size)\n",
    "  for word in comment:\n",
    "    try:\n",
    "      comment_vector += model.wv[word]\n",
    "    except KeyError:\n",
    "      # Ignore words not in the vocabulary\n",
    "      pass\n",
    "  average_vectors.append(comment_vector / len(comment))\n",
    "\n",
    "# Display the average vector for the first comment\n",
    "print(\"Average vector for first comment:\", average_vectors[0])\n",
    "print(\"Average vector for first comment:\", average_vectors[1])\n",
    "print(\"Average vector for first comment:\", average_vectors[2])\n",
    "print(\"Average vector for first comment:\", average_vectors[3])\n",
    "print(\"Average vector for first comment:\", average_vectors[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk about a \"100-dimensional vector,\" we're referring to a list or array of 100 numbers, each representing a point in some dimensional space. A word vector in such a space encapsulates various aspects of the word's meaning and usage.\n",
    "\n",
    "Understanding Dimensions and Averaging\n",
    "Let's say we have 3 words, each represented by a 4-dimensional word vector (for simplicity, we're using 4 dimensions instead of 100):\n",
    "\n",
    "- Word 1 vector: [1,2,3,4]\n",
    "- Word 2 vector: [2,3,4,5]\n",
    "- Word 3 vector: [3,4,5,6]\n",
    "  \n",
    "These vectors might be the embeddings for three words in a sentence. To represent the entire sentence by a single vector, we compute the average of these vectors.\n",
    "\n",
    "To find the average vector, we calculate the mean for each dimension across all word vectors:\n",
    "\n",
    "- Dimension 1 average: (1+2+3)/3=2\n",
    "- Dimension 2 average: (2+3+4)/3=3\n",
    "- Dimension 3 average: (3+4+5)/3=4\n",
    "- Dimension 4 average: (4+5+6)/3=5\n",
    "  \n",
    "So, the average vector representing the entire sentence is [2,3,4,5].\n",
    "\n",
    "What This Represents? This averaged vector is still in the same 4-dimensional space as the original word vectors, but it's a new vector that, in theory, captures the combined semantic and syntactic essence of all the words in the text.\n",
    "\n",
    "These average vectors are also known as \"sentence embeddings\" so that when they append they create the input for a classifier that can classify the entire sentence.\n",
    "\n",
    "Here is the entire code using logistic regression as classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/YigitAydede/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/YigitAydede/anaconda3/envs/nlp_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/YigitAydede/anaconda3/envs/nlp_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/YigitAydede/anaconda3/envs/nlp_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "\n",
    "# Download NLTK punkt tokenizer models\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the dataset\n",
    "comments = [\"love the new features\", \"hate the long wait time\", \"excellent service\", \"poor experience with the product\", \"happy with the purchase\"]\n",
    "sentiments = [1, 0, 1, 0, 1]  # 1: Positive, 0: Negative\n",
    "\n",
    "# Tokenize comments\n",
    "tokenized_comments = [word_tokenize(comment.lower()) for comment in comments]\n",
    "\n",
    "# Train Word2Vec embeddings\n",
    "model = Word2Vec(tokenized_comments, vector_size=4, window=2, min_count=1, workers=1)\n",
    "\n",
    "# Function to convert a comment to its average word vector\n",
    "def comment_to_vector(comment):\n",
    "    comment_vector = np.zeros(model.vector_size)\n",
    "    for word in comment:\n",
    "        if word in model.wv:\n",
    "            comment_vector += model.wv[word]\n",
    "    return comment_vector / len(comment)\n",
    "\n",
    "# Convert all tokenized comments to average word vectors\n",
    "average_vectors = [comment_to_vector(comment) for comment in tokenized_comments]\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(average_vectors, sentiments, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code that uses TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/YigitAydede/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/YigitAydede/anaconda3/envs/nlp_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/YigitAydede/anaconda3/envs/nlp_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/YigitAydede/anaconda3/envs/nlp_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "\n",
    "# Download NLTK punkt tokenizer models\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the dataset\n",
    "comments = [\"love the new features\", \"hate the long wait time\", \"excellent service\", \"poor experience with the product\", \"happy with the purchase\"]\n",
    "sentiments = [1, 0, 1, 0, 1]  # 1: Positive, 0: Negative\n",
    "\n",
    "# Tokenize comments (though it's not strictly necessary with TfidfVectorizer)\n",
    "tokenized_comments = [\" \".join(word_tokenize(comment.lower())) for comment in comments]\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the comments to get TF-IDF vectors\n",
    "tfidf_vectors = vectorizer.fit_transform(tokenized_comments).toarray()\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vectors, sentiments, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Differences:\n",
    "\n",
    "1. Text Representation:\n",
    "\n",
    "- TF-IDF: Converts the text data into sparse vectors where each feature represents a word and its corresponding importance in the document (based on term frequency and inverse document frequency). The resulting vectors are high-dimensional and sparse.\n",
    "- Word2Vec (Example 2): Converts each word into a dense vector (embedding) that captures semantic meaning. The final document vector is an average of all word embeddings in the document, producing a dense, lower-dimensional vector.\n",
    "\n",
    "2. Vectorization Approach:\n",
    "\n",
    "- TF-IDF: The focus is on the importance of words within the document and across the corpus. Words that occur frequently in a document but rarely across the entire dataset have high scores.\n",
    "- Word2Vec: Focuses on capturing the relationships and meanings of words based on their context within sentences. Words with similar contexts have similar vector representations, capturing semantic similarities.\n",
    "\n",
    "3. Model Input:\n",
    "\n",
    "- TF-IDF: Produces a sparse, high-dimensional feature vector where each dimension corresponds to a specific word in the corpus (e.g., 5000 dimensions if max_features=5000).\n",
    "- Word2Vec: Produces a dense, lower-dimensional vector (e.g., 100 dimensions if vector_size=100) that is an average of the word embeddings in the document.\n",
    "\n",
    "4. Semantic Understanding:\n",
    "\n",
    "- TF-IDF: Doesn’t capture semantic similarities between words. For instance, \"great\" and \"excellent\" will be treated as completely different features.\n",
    "- Word2Vec: Captures semantic similarities between words. If \"great\" and \"excellent\" have similar contexts in the training data, their embeddings will be similar.\n",
    "\n",
    "5. Training and Computation:\n",
    "\n",
    "- TF-IDF: Faster and simpler to compute. No additional model needs to be trained, as it’s purely a statistical method.\n",
    "- Word2Vec: Requires training the Word2Vec model on the text data, which can be computationally intensive depending on the dataset size and vector dimensions.\n",
    "\n",
    "6. When to Use Each Approach:\n",
    "\n",
    "- TF-IDF: Suitable for traditional machine learning approaches, especially when the focus is on word importance rather than word relationships. It works well with large corpora and can be a strong baseline.\n",
    "- Word2Vec: Preferred when you need to capture more nuanced relationships between words and their contexts. It’s useful when semantic meaning plays an important role in your classification task.\n",
    "\n",
    "**Which Approach Is Better?**\n",
    "\n",
    "- For Simplicity: TF-IDF is easier to implement and understand, and it works well as a baseline for many text classification tasks.\n",
    "- For Capturing Semantic Relationships: Word2Vec is better when the relationships between words are important (e.g., understanding that \"excellent\" and \"great\" are similar even if they don’t co-occur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Large Movie Review Dataset v1.0\n",
    "\n",
    "Dowbload the data from the link below.\n",
    "https://ai.stanford.edu/~amaas/data/sentiment/ \n",
    "\n",
    "The IMDB Large Movie Review Dataset is a benchmark dataset used extensively for sentiment analysis tasks. It contains movie reviews labeled by sentiment polarity (positive or negative), making it ideal for training and evaluating sentiment classification models.\n",
    "\n",
    "1. Dataset Composition\n",
    "Total Reviews: 50,000 labeled movie reviews.\n",
    "Training Set: 25,000 reviews, balanced with 12,500 positive and 12,500 negative samples.\n",
    "Test Set: 25,000 reviews, balanced with 12,500 positive and 12,500 negative samples.\n",
    "Unlabeled Data: An additional 50,000 unlabeled reviews are available for unsupervised learning.\n",
    "2. Sentiment Labeling Criteria\n",
    "Positive Reviews: Reviews with a rating of 7 or higher out of 10.\n",
    "Negative Reviews: Reviews with a rating of 4 or lower out of 10.\n",
    "Neutral Reviews Excluded: Reviews with ratings between 5 and 6 are not included in the labeled dataset to ensure clear sentiment polarity.\n",
    "3. Dataset Structure\n",
    "The dataset is organized into two main directories: train and test. Each of these directories contains two subdirectories, pos and neg, corresponding to positive and negative reviews, respectively.\n",
    "\n",
    "The directory structure is as follows:\n",
    "aclImdb/\n",
    "    train/\n",
    "        pos/  (12,500 positive reviews)\n",
    "        neg/  (12,500 negative reviews)\n",
    "    test/\n",
    "        pos/  (12,500 positive reviews)\n",
    "        neg/  (12,500 negative reviews)\n",
    "\n",
    "Each review is stored as a plain text file, with the file name following the convention [id]_[rating].txt. For example:\n",
    "\n",
    "200_8.txt is a positive review from the test set with an ID of 200 and a rating of 8 out of 10.\n",
    "4. Dataset Characteristics\n",
    "Balanced Classes: The dataset is balanced, with an equal number of positive and negative reviews in both the training and test sets.\n",
    "Diversity in Reviews: No more than 30 reviews are included for any single movie to prevent biases from repeated reviews.\n",
    "Disjoint Movie Sets: The training and test sets contain reviews from completely different movies to avoid model overfitting based on movie-specific language.\n",
    "5. Use in Sentiment Analysis\n",
    "The IMDB dataset is widely used as a benchmark for binary sentiment classification. It provides a challenging testbed for models because of the informal, nuanced, and varied language used in movie reviews. Models trained on this dataset aim to classify the sentiment of a review as either positive or negative based solely on the text content.\n",
    "\n",
    "6. Available Features and Additional Files\n",
    "In addition to the raw text reviews, the dataset includes:\n",
    "\n",
    "Bag-of-Words Features: Preprocessed bag-of-words (BoW) representations are available in .feat files.\n",
    "Vocabulary: A vocabulary file (imdb.vocab) lists all words used in the dataset, which can be used for feature extraction and analysis.\n",
    "Expected Ratings (imdbEr.txt): This file provides the expected sentiment rating for each word in the vocabulary, based on prior studies.\n",
    "7. Citation\n",
    "If you use the IMDB dataset in your research or projects, please cite the following paper:\n",
    "Maas, Andrew L., et al. \"Learning Word Vectors for Sentiment Analysis.\" Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/YigitAydede/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8718\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      2482\n",
      "           1       0.87      0.88      0.87      2518\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data files if not already downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the IMDB dataset\n",
    "dataset = load_files('/Users/YigitAydede/Library/CloudStorage/Dropbox/Documents/Courses/MBAN/NLPBootcamp/Section4/aclImdb/train', categories=['pos', 'neg'], shuffle=True, encoding='utf-8', decode_error='ignore')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
